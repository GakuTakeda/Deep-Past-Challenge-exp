data:
  train_path: "../data/train.csv"
  val_ratio: 0.1

model:
  name: "google/byt5-small"
  task_prefix: "translate Akkadian to English: "

tokenizer:
  max_source_length: 512
  max_target_length: 512

training:
  output_dir: "./exp2/output"
  num_train_epochs: 20
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 8
  learning_rate: 3e-4
  weight_decay: 0.01
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  fp16: false
  generation_num_beams: 4
  logging_steps: 10
  save_total_limit: 3
  early_stopping_patience: 5
  dataloader_num_workers: 2
  seed: 42
